# EE 360C Lecture -- 1.31.17

## Implementation of the Gale-Shapely Algorithm

Do all executions of this algorithm yield the same matching?

Prove the following claim: all executions of the GS algorithm yield a
man-optimal assignment-- that is, every man receives the best valid partner.

- Proof by contradiction: a man does not receive the best valid partner. 

  Consider a group of three men and three women. A man *not* receiving the best
  valid partner means that for pairs {m, w} and {m', w'}, m had w' ranked more
  highly on his list of preferences and m' was not ranked more highly than
  him. Since men propose in order of preference and women accept the first
  proposal, m will receive his first choice unless someone more highly ranked
  than him proposes as well. It is impossible for the above match to exist
  since m will have proposed to w'; if he was the first, w' would accept the
  proposal and m' would not be able to take his place. If he was second, m'
  would be bumped in favor of m. Therefore, a suboptimal pairing for the man is
  not possible-- each man will be assigned to the most highly ranked valid
  partner.

- Class Proof:

  Suppose excution leads to S where a man is not paired with his best valid
  partner, meaning he was rejected by a valid partner. Consider the first time
  m is rejected by valid partner w, forming or continuing an engagement with a
  man m' whom she prefers to m. Since w is a valid partner for m, there must
  exist a stable match S' containing (m,w) and m' paired with w' (not w).

  Rejection of m is first rejection of a valid partner, m' must not be rejected
  by any valid partner when he became engaged to w. Since m' proposed in
  decreasing order, thus he prefers w to w'. However, since (m',w) do not exist
  in S', there is an instability S', contradicting our initial assumption.

A key observation about the "stable roommate problem" (where each person is in
a single pool rather than a bipartite setup) is that a stable matching doesn't
always exist.

Steps in algorithm design:

- Formulate the problem precisely

- Design an algorithm for the problem

- Prove the algorithm correct

- Give a bound on the algorithm's running time

## Algorithms and Analysis: The Basics

Def. *algorithm*: Any well-defined computational procedure that takes
some value or set of values as input and produces some value or set of values
as output.

- An algorithm is *correct* if, for every input instance, it halts with the
  correct output

- is said to *solve* a computational problem if it is correct

*Algorithm analysis* refers to predicting the resources (memory, communication
bandwidth, computer hardware) that the algorithm requires.

What is an *efficient* algorithm?

- Vague, not so good description: "efficiency  means it runs quickly on real
  input instances."

- A better definition of efficiency would be:

    - platform-independent

    - instance-independent

    - of predictive value with respect to increasing instance sizes

- The *running time* of an algorithm depends on the number of primitive
  operations or "steps" that are executed.

    - Should also be machine independent

    - Assume a constant amount of time required to execute each line of
      pseudocode

- The *worst case* running time of an algorithm is the worst possible running
  time the algorithm could have over all inputs of size N

    - This tends to be a better measure than the average case running time

- Slightly better definition: An algorithm is efficient if it achieves
  qualitatively better worst-case performance, at an analytical level, than
  brute-force search.

    - This is still pretty vague. What defines "qualitatively better?"

- Desirable Scaling Property

    - When the input size doubles, the algorithm should only slow down by a
      constant factor C. An algorithm is considered *poly-time* if this
      condition holds true.

We will be studying *asymptotic efficiency* of algorithms (i.e. how well does
it scale with increasing input size?)

- Asymptotic upper bound: Big O Notation

- Asymptotic lower bound: Big Omega Notation

- If a function is O(g(n)) and Omega(g(n)), then f(n) = Theta(g(n)) (a "tight
  bound")
