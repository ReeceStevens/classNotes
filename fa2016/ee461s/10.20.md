# EE 461S Lecture -- 10.20.16

## Last Time

We looked at concurrency using threads

Next of the three steps:

- Virtualization of Memory via VM

- Virtualization of CPU via scheduling

- ***Virtualization of the CPU by threads***

## Schedule

Focus of the next three weeks: race conditions

- What are they?

- When do they occur?

- How do we avoid them?

Topics:

1. Threads

2. Locks

3. Condition variables

4. Semaphores

## Threads

*Thread* (def): a context of execution which shares the address space with its
creator but has its own stack.

- We'll view it as a function that runs independently

```
Single-threaded process

    main()
     |
     |
     |
     subroutine() ------------|
                              |
                              |
     PC<----------------------return
     |
     |
     v
```


```
Multi-threaded process

    main()
     |
     |     Code and heap are shared
     |
     create thread ------------|
     |                         | has its own stack
     |                         |
     |                         return
     |
     | anything in the shared heap could cause a concurrency issue
     v
```

*Thread-safe* (re-entrant)

- Let's say a thread makes a system call to `sleep()`

- Reentrant code means: if two independent threads call the same code, there's
  no conflict

- If a call is *not* thread-safe, do not use it (or use it at your own risk)
  inside a thread's function

    - Leads to non-deterministic behavior

The common API for threads among all POSIX systems is `pthreads`

- `int pthread_create(pthread_t* T, const pthread_attr_t* attr,
        (void*) *func(void*), void* arg)`

    - We will always pass null for `attr`

    - `func`: the function the thread will execute

    - `arg`: what is passed to the function

- `pthread_join(pthread_t* T, (void**) retval)`

    - join is a blocking system call-- it will wait until the child returns

- `pthread_exit(void* retval)`

Need some sort of mechanism for handling concurrency:

1. Locks

    - `pthread_mutex_init = PTHREAD_MUTEX_INITIALIZER;`

    - `pthread_mutex_lock(pthread_mutex_t* m)`

    - `unlock`

    *mutex* stands for "mutual exclusion"

    Any code that has the potential for a race condition will be called a
    critical section. We we can wrap it inside calls to `pthread_mutex_lock`
    and `pthread_mutex_unlock`

```c
#include <pthread.h>

pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;

void *thr_func(void* arg) {
    pthread_mutex_lock(&lock);
    // ... do critical section stuff
    pthread_mutex_unlock(&lock);
}
```

2. Condition variables (won't get to this today)

### How are locks implemented?

Simplest implementation (v0):

```c
/* Coarse-grained locking mechanism */
lock() {
    disableInterrupts();
}
unlock() {
    enableInterrupts();
}
```

v1 solution:

```c
/* Fine-grained locking mechanism */
typedef struct {
    int flag;
} lock_t;

void init(lock_t* mutex) {
    mutex->flag = 0; // 0 means it is free, 1 means it's being held
}

void lock(lock_t* mutex) {

}

void unlock(lock_t* mutex) {
    mutex->flag = 0;
}

// Usage example

lock_t m;
init(&m);
lock(&m);
// critical section code
unlock(&m);

```

Evaluating a locking solution? Questions you should ask:

- Does it really provide mutual exclusion? (correctness)

- Do the processes wait reasonable amounts of time? (fairness)

    - i.e. turn based vs. thread starvation

- Performance

We now have hardware support for atomic lock instructions

- `ldstub` in SPARC

- `xchg` in x86

Both of these are test-and-set operations (check a variable and set it in an
antomic operation)
